{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM04Ctm+7yBXGKeWDzcA+jw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beyza720/nlphw2/blob/main/inference_pipeline_power.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_path = '/content/drive/My Drive/Colab Notebooks/power-lv-train.tsv'\n",
        "train_power_data = pd.read_csv(train_path, sep='\\t')\n",
        "\n",
        "# Class imbalance for power, same as the fine-tune a multilingual masked language model task\n",
        "class_0 = train_power_data[train_power_data['label'] == 0]\n",
        "class_1 = train_power_data[train_power_data['label'] == 1]\n",
        "\n",
        "class_1_oversampled = resample(class_1, replace=True, n_samples=len(class_0), random_state=42)\n",
        "balanced_train_power_data = pd.concat([class_1_oversampled, class_0])\n",
        "\n",
        "# splitting the data 0.9 for training and 0.1 for testing\n",
        "train_power, val_power = train_test_split(\n",
        "    balanced_train_power_data,\n",
        "    test_size=0.1,\n",
        "    stratify=balanced_train_power_data['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "text = val_power['text'].tolist()\n",
        "text_en = val_power['text_en'].tolist()\n",
        "\n",
        "# access token for the model\n",
        "login(token=\"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\")\n",
        "\n",
        "pipe = pipeline(\n",
        "    model=\"meta-llama/Llama-3.2-1B\",\n",
        "    # to use gpu\n",
        "    device=0,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipe.tokenizer.pad_token_id = pipe.model.config.eos_token_id\n",
        "pipe.tokenizer.padding_side = 'left'\n",
        "\n",
        "\n",
        "results_text = pipe(text, max_new_tokens=100, temperature=0.7, batch_size=8)\n",
        "results_text_en = pipe(text_en, max_new_tokens=100, temperature=0.7, batch_size=8)\n",
        "\n",
        "predicted_labels_text = [\n",
        "    1 if \"right\" in result[0]['generated_text'].lower() else 0 for result in results_text\n",
        "]\n",
        "predicted_labels_en = [\n",
        "    1 if \"right\" in result[0]['generated_text'].lower() else 0 for result in results_text_en\n",
        "]\n",
        "\n",
        "true_labels = val_power['label'].tolist()\n",
        "\n",
        "print(\"Accuracy (text):\", accuracy_score(true_labels, predicted_labels_text))\n",
        "print(\"Accuracy (text_en):\", accuracy_score(true_labels, predicted_labels_en))\n",
        "print(\"\\nClassification Report (text):\")\n",
        "print(classification_report(true_labels, predicted_labels_text))\n",
        "print(\"\\nClassification Report (text_en):\")\n",
        "print(classification_report(true_labels, predicted_labels_en))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQWQXOj_la24",
        "outputId": "5f6156e9-7d60-45ad-caf0-0ad0ce495718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (text): 0.5026455026455027\n",
            "Accuracy (text_en): 0.49206349206349204\n",
            "\n",
            "Classification Report (text):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.99      0.67        95\n",
            "           1       0.50      0.01      0.02        94\n",
            "\n",
            "    accuracy                           0.50       189\n",
            "   macro avg       0.50      0.50      0.34       189\n",
            "weighted avg       0.50      0.50      0.35       189\n",
            "\n",
            "\n",
            "Classification Report (text_en):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.61      0.55        95\n",
            "           1       0.49      0.37      0.42        94\n",
            "\n",
            "    accuracy                           0.49       189\n",
            "   macro avg       0.49      0.49      0.48       189\n",
            "weighted avg       0.49      0.49      0.48       189\n",
            "\n"
          ]
        }
      ]
    }
  ]
}